# Ollama API

![Ollama](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTCnTSM4MHExKgIkfUheyQ04byO32OaUXmQVg&s)

A lightweight API service for running Large Language Models locally.

Unleash the power of local LLMs with Nosana! Effortlessly run your Ollama API instance on high-performance GPU-backed nodes, ensuring optimal inference for your applications.

## Key Features
- Multiple model support
- RESTful API
- Low resource usage
- Easy model management
- GPU acceleration support

## Configuration
- Port: 11434
- GPU: Required
- API endpoint access