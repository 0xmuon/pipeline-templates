# LMDeploy API

LMDeploy is a high-performance inference engine for Large Language Models (LLMs). It provides quantization, optimization, and serving capabilities to efficiently deploy LLMs in production environments.

## Key Features
- Optimized inference engine for LLMs
- Support for various model architectures
- Built-in quantization capabilities
- RESTful API interface
- GPU acceleration support

## Configuration
- Port: 23333
- Model: Qwen2.5-7B
- GPU: Required 