# LMDeploy API

![LMDeploy](https://avatars.githubusercontent.com/u/135356492?s=280&v=4)

A high-performance inference engine for Large Language Models with advanced optimization features.

Unleash the power of LLMs with Nosana! Effortlessly deploy your models on high-performance GPU-backed nodes, ensuring optimal inference speed for your applications.

## Key Features
- Optimized model inference
- Quantization support
- RESTful API interface
- Multi-model serving
- GPU acceleration support

## Configuration
- Port: 23333
- GPU: Required
- Model: Qwen2.5-7B