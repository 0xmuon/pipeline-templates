{
  "version": "0.1",
  "type": "container",
  "meta": {
    "trigger": "dashboard",
    "system_requirements": {
      "required_vram": 16
    }
  },
  "ops": [
    {
      "type": "container/run",
      "id": "llama8b",
      "args": {
        "entrypoint": [],
        "cmd": [
          "/bin/sh",
          "-c",
          "python3 -m vllm.entrypoints.openai.api_server --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B --served-model-name R1-Llama-8B --port 9000"
        ],
        "image": "docker.io/vllm/vllm-openai:v0.7.2",
        "gpu": true,
        "expose": 9000
      }
    }
  ]
} 